---
date: 2025-10-10 15:58:42 +0000
excerpt: 'Пост рассказывает о практическом применении языковых моделей (LLM) в различных
  рабочих процессах: от подготовки докладов и управления алертами до автоматизации
  коммуникаций и разметки медицинских данных. Продемонстрированы кейсы, где LLM помогают
  существенно сократить время на рутинные задачи и повысить эффективность работы в
  разных областях.'
layout: post
source_type: telegraph
source_url: https://telegra.ph/Kak-ya-ispolzuyu-LLM-10-09
tags:
- жека
- llm
telegram_url: https://t.me/varim_ml/165
telegraph_url: https://telegra.ph/Kak-ya-ispolzuyu-LLM-10-09
title: LLM в рабочих задачах и процессах
views: 3089
---

# LLM в рабочих задачах и процессах  




LLM плотно вошли в мою повседневную и рабочую жизнь. Про ИИ в разработке я уже рассказывал, в жизни тоже ChatGPT вытеснил Гугл процентов на 80 - от медицинских вопросов до помощи в придумывании игр на праздники. Но есть и много других интересных применений на работе, про некоторые за последний месяц я и хочу рассказать. Все эти кейсы позволили сэкономить кучу времени на задачах, на которые раньше бы ушли часы и дни.

#### Инсайты для доклада

![](/assets/images/5582e158.png)

Нужно тут было экстренно подготовить докладик на медицинскую конференцию, тему выбрал такую - "Хорошие практики проектирования и разработки LLM-систем в медицине". Какие-то идеи были, но как-то всё не складывалось в общую картинку, нужны были ещё мысли, чтоб связать всё это в единую историю.

Попросил Cursor подцепить все треды из канала в Маттермосте, где обсуждается проект по протоколированию приёма врача и пациента. Для каждого треда выделяю с помощью LLM топ-инсайты, исходя из темы доклада. Промпт слегка подкорректировал, в остальном ни строчки кода не пришлось писать самому.

В итоге получился огромный маркдаун на несколько десятков страниц. Всё это, конечно, пришлось прочитать и сгруппировать самому, но это всё равно в разы быстрее, чем читать все треды и выделять из них какие-то генерализируемые советы.

Доклад в итоге вышел на 50 минут, так что пришлось резать втрое, но тема явно рабочая, рекомендую.

#### LLM Alert Manager

![](/assets/images/a0f797fd.png)

Раньше у нас все алерты из Графаны отправлялись в специальный канал каждого проекта, и это было жутко неудобно - если одна инфраструктурная проблема затрагивала сразу несколько направлений (а так чаще всего и происходит), то обсуждение начиналось сразу в нескольких местах. Захотелось группировать все связанные алерты вместе в одном треде Маттермоста. Прописать руками все правила группировки, научиться парсить тексты алертов (где-то написано "один час", где-то "60 минут", где-то "Mosmed", где-то "МосМедИИ"), создать какой-то инструмент управления жизненным циклом инцидентов - возможно, но очень лень. Поэтому на помощь снова приходит LLM:

  * группирует вместе связанные алерты по прописанной логике, включая вероятную причину возникновения алерта
  * формирует нужный SQL-запрос по шаблону (такой-то кастомер, такой-то временной интервал) и достаёт из БД статистики информацию по ошибкам и по времени выполнения разных этапов обработки
  * определяет критичность инцидента по правилам + сравнивая текущие проблемы с исторической информацией (например, в 4 утра в воскресенье нулевой поток - это норма)
  * формулирует причину возникновения понятным текстом
  * понимает сообщения дежурных на естественном языке ("снизь критичность до зелёной", "причина в падении нейронки по ММГ") и обновляет информацию об инциденте



Повторюсь, большую часть этой логики можно было бы захардкодить (и часть со временем переведём на фиксированную), но для быстрого старта LLM здесь очень помог - а ещё и понимает естественный язык.

#### n8n в Маттермосте

![](/assets/images/78401ed8.png)

Давно хотел попробовать [n8n](https://n8n.io/) и наконец-то затестил на Маттермосте:

  * Можно написать thread_summary - выдаст саммери длинной переписки, очень удобно, когда хочется быстро понять контекст треда на 300 сообщений
  * thread_insight - выдаст какой-нибудь полезный инсайт по треду. Часто очень точно попадает в самую суть. Но больше игрушка, конечно.
  * kacher_llm - может отвечать на сообщения в стиле одного из наших сотрудников. Кидает в контекст 100 случайных цитат человека и отвечает на тред в его стиле. В основном ругается на нас матом.



К сожалению, в коннекторе Маттермоста многое было не реализовано, так что пришлось немножко пописать запросы в API и код на JS. Но в целом потенциал у инструмента огромный для самых разных задач, связанных с автоматизацией.

#### Разметка по текстовым заключениям рентгенолога

Недавно скачали датасет с 30 тысячами текстовых заключений врача-рентгенолога, и для хакатона нужно было оперативно выдрать из них бинарные метки ("абсолютная норма" или "патология") и список патологий из заранее определённого. Gemini 2.5 Flash + Structured Output - и проблема решена за копейки за 10 минут. Качество крайне достойное, так как и сама задача несложная - пришлось только составить хороший промпт с примерами - что считается патологией, а что нет.

#### Morphik

![](/assets/images/2ffe91dc.png)

Когда запускали в компании ИИ-вики на основе [Onyx](https://github.com/onyx-dot-app/onyx), довольно быстро стало понятно, что ответы на большую часть задаваемых вопросов кроются где-то внутри разных документов со сложной структурой - PDF, презентации, таблицы, вордовские документы. Из коробки для парсинга таких документов там используется Unstructured - и он мне не очень нравится. Давно хотел затестить [ColPali](https://arxiv.org/abs/2407.01449), а он в Морфике поддерживается из коробки. Это штука, которая не делает OCR или сложный парсинг, а просто эмбеддит картинку. В итоге каждая страница документа превращается в набор векторов (каждый соответствует части страницы). На инференсе эмбеддим запрос и находим страницы, на которой есть патчи, наиболее соответствующие запросу. Нужные страницы дальше так же можем запихнуть в контекст как картинку или извлечь из неё текст (зависит от задачи).

![](/assets/images/3ab1f2be.png)

Первые результаты впечатлили - итоговая система умеет находить релевантные страницы и хорошо отвечать на вопросы, которые требуют понимания сложных таблиц даже в сканированных документах.
