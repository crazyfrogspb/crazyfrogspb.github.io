---
date: 2022-10-12 15:59:56 +0000
excerpt: 'Про metric learning   Миша   В последнее время я что-то совсем мало делал
  для канала: переезд в другую страну дело не самое лёгкое. Но теперь опять...'
layout: post
source_type: telegraph
source_url: https://telegra.ph/Pro-metric-learning-10-07
tags:
- cv
- обзор
- миша
telegram_url: https://t.me/varim_ml/67
telegraph_url: https://telegra.ph/Pro-metric-learning-10-07
title: Про metric learning
views: 0
---

# Про metric learning  


Миша  


В последнее время я что-то совсем мало делал для канала: переезд в другую страну дело не самое лёгкое. Но теперь опять появились силы что-то сюда написать, так что расскажу вам чем я занимался последние пару месяцев.

На новой работе я всё так же занимаюсь CV, но теперь это метрик лёрнинг и домен больше не медицина.

Что же это за задача такая? Объясняю на картинке, но сразу оговорюсь: под метрик лёрнингом дальше буду только домен картиночек, потому что мне он ближе и чаще под этим термином подразумевают именно его.

#### Про задачу

![](/assets/images/68c920e4.png)

Рассмотрим несколько объектов разных категорий (здесь зелёные и красные). Мы хотим сделать генератор эмбеддингов для объектов, такой, чтобы по выбранной метрике объекты одной категории лежали близко, а объекты разных категорий — далеко. Строго говоря, это не совсем корректное определение метрик-лёрнинга, но наиболее понятное и вполне валидное на практике*****.

Сразу встаёт вопрос "почему бы нам не обучить классификатор на два этих класса и просто брать их эмбеддинги?" Всё дело в том, что мы рассчитываем, что может появиться какой-то дополнительный класс, например, синий. В этом случае никто нам не гарантирует, что сетка не положит его в кучу к красным или зелёным объектам. Понять, где же это может использоваться легко вспомнив Google Lens:

![](/assets/images/179705de.jpg)

Lens умеет достаточно неплохо находить совершенно разные объекты на картинке: технику, достопримечательности, мебель и так далее. Научить классификатор на такое большое (и постоянно растущее) кол-во классов просто не получится. Другими хорошими примерами использования могут быть [ReID](https://paperswithcode.com/task/person-re-identification), [сравнение птичек](https://paperswithcode.com/dataset/cub-200-2011), [поиск похожей одежды](https://mmlab.ie.cuhk.edu.hk/projects/DeepFashion/InShopRetrieval.html) и так далее. Таким образом, метрик лёрнинг — это про:

  1. Поиск ближайших соседей.
  2. Кластеризацию объектов.
  3. Снижение размерности (например, [превращение картинок в небольшие эмбеддинги](https://www.kaggle.com/competitions/google-universal-image-embedding)).



И, наконец, что (как мне кажется) чаще всего используется на практике:

4\. Скормить хорошие фичи объектов в какой-нибудь другой МЛ пайплайн в надежде, что метрики вырастут.

Последнее может быть особенно полезно, если вы не знаете как же использовать картинки ваших товаров в предсказании спроса ;)

Однако, метрик лёрнинг — это не всегда про supervised learning, это ещё иногда и про weakly supervised. В этом случае у нас нет разметки "объект **a** имеет категорию **1** , а объект **b** категорию **2** ", мы можем иметь разметку на пары (объекты принадлежат одной категории / разным категориям), триплеты (например, первые два объекта ближе друг к другу, чем к третьему) и так далее.

Наконец, хорошо бы отделить метрик лёрнинг от нескольких очень похожих задач: Self-Supervised Learning и Information (а в нашем случае Image) Retrieval.

С SSL всё понятно: он отличается тем, что это unsupervised задача. С IR разница более тонкая и, я бы сказал, зависящая от цели применения: если мы учим сетку, для того, чтобы в целом считать дистанцию между любыми объектами нашего домена, то это метрик лёрнинг, если же мы хотим для новых изображений искать ближайшие в нашей базе данных, то это уже скорее image retrieval.

#### Немного про терминологию 

Теперь, когда мы немного обсудили формулировку задачи, давайте обсудим классическую терминологию для метрик лёрнинга.  
**Query** — объект, для которого мы ищем похожие в **Gallery** — наборе объектов, часть из которых похожа на query. Часто для обучения применяется триплет лосс — лосс на трёх объектах, их называют **anchor, positive, negative. Anchor** — объект для которого ищутся poistive и negative. **Positive** — объект той же категории, что и anchor. **Negative** — объект категории, отличной от anchor.

#### Про метрики

В целом, в метрик лёрнинг сравниваются по некоторым метрикам из IR и ReID: Recall@k (он же Precision@k), MAP@k, CMC@k (был ли релевантный объект среди ближайших k).

Почему-то при этом в метрик лёрнинге принято сравнивать модели по Recall@1 (он же Precision@1, он же CMC@1, он же MAP@1): процент пар query-ближайший объект из gallery, где категории совпадают. Метрика, конечно, хорошо интерпретируемая, но очень шумная, на картинке показано почему.

![](/assets/images/db008026.png)

В каждой строке i показаны топ-5 ближайших объектов к query_i, слева направо. Единица обозначает то, что объект той же категории, что и query, иначе ноль.  
Для модели 1 R@1 > чем у модели 2, однако интуитивно модель 2 кажется лучше. Такое может случиться, например, из-за шумной разметки.

Поэтому если вы хотите использовать out-of-the-box метрику, стоит использовать хотя бы MAP@k, а ещё лучше — задизайнить свою. Например, если вы хотите показывать юзеру в рекомендациях 3 слота для похожих объектов, то прекрасной метрикой может быть комбинация из P@3 и MAP@4-10: считаем пресижн на первых трёх и взвешенно добавляем к нему мап по урезанному списку: от 4 объекта до 10-го. Таким образом мы не только будем иметь представление о том, сколько релевантных объектов среди наших слотов показала модель (юзер всё равно увидит все три и порядок не так важен), но и немного обращать внимание на то, что идёт после первых трёх объектов (избегать ситуацию с картинкой выше).

#### Про подходы

Глобально их 2: 

  1. Контрастив
  2. Классификация



Но если разбираться чуть глубже, то среди контрастив подхода можно увидеть достаточно чёткое разделение на подгруппы по лоссам: парные, триплет и остальные.

Давайте сначала про **классификацию** , потому что она проще. Метрик лёрнинг как классификация часто использовался для распознавания лиц, поэтому и статьи про него обычно называются *Face: ArcFace, CosFace, SphereFace, ElasticFace, BroadFace, UniformFace, RegularFace, CenterLoss. По сути это всё способы модифицировать классические классификационные лоссы для их применения в метрик лёрнинг, с надеждой, что эмбеддинги выучатся как раз такие, что похожие объекты лежат рядом, не оптимизируя это напрямую. Из статей рекомендую прочитать [ArcFace](https://arxiv.org/pdf/1801.07698.pdf) (как одну из наиболее знаковых), [CenterLoss](https://arxiv.org/pdf/2104.13643.pdf) (потому что простая идея, которая работает хорошо) и одну из [UniformFace](https://openaccess.thecvf.com/content_CVPR_2019/papers/Duan_UniformFace_Learning_Deep_Equidistributed_Representation_for_Face_Recognition_CVPR_2019_paper.pdf) / [RegularFace](https://openaccess.thecvf.com/content_CVPR_2019/papers/Zhao_RegularFace_Deep_Face_Recognition_via_Exclusive_Regularization_CVPR_2019_paper.pdf) (потому что у них в чём-то похожие неплохие идеи). На бенчмарках классификация уже давно уехала куда-то вниз и сейчас не так популярна как была когда-то.

Популярен сейчас **контрастив** , но если уходить в него**** глубоко, то тут чёрт ногу сломит: статей миллион.

![](/assets/images/553f2d29.png)Когда писал про миллион, думал что образно

Как я уже говорил, существует как минимум несколько больших групп по лоссам: основанные на триплетах, основанные на парах и все остальные. Лоссы, основанные на парах пытаются напрямую оптимизировать постановку задачи: если объекты в паре принадлежат одному классу, то мы стараемся притянуть их друг к другу, если наоборот — разнести их как можно дальше. Самый простой и банальный парный лосс буквально делает это:

![](/assets/images/7be2933a.png)

Про терминологию триплетов я так же упоминал выше: у нас есть **a** nchor, **p** ositive и **n** egative. Все лоссы этой категории пытаются сделать так, чтобы ReLU(d(a, p) - d(a, n) + ε) был минимальным (здесь d(·, ·) — какая-то дистанция), то есть чтобы дистанция от анкора до позитива была меньше дистанции до негатива.

Как вы наверное заметили, в простых вариациях и парного, и триплет лосса есть какой-то странный гиперпараметр ε, зачем же он нам? Представьте, вы — типичная ленивая сетка, которой не хочется ничего учить, как вам минимизировать лоссы выше, если бы в них не было +ε? Правильно, выдавать абсолютно одинаковые эмбеддинги на всё, в этом случае лосс будет ровно ноль, удобно. 

Кроме того, в контрастив-подходах остро стоит проблема формирования триплетов и пар: если давать сетке слишком простые примеры (например, выбирать негативный пример случайно), то ей будет просто и она вряд ли выучит что-то полезное быстро. Для этого в контрастив подходах используется майнинг примеров, то есть подбор _хороших_ триплетов и пар (например, хардмайнинг, когда для случайно выбранного анкора выбирается максимально близкий негативный и максимально далёкий позитивный пример).

Хорошими статьями для погружения в этот подход будут: [первая статья про пэйрвайс подход](https://www.researchgate.net/publication/4156225_Learning_a_similarity_metric_discriminatively_with_application_to_face_verification), [FaceNet](https://arxiv.org/pdf/1503.03832.pdf) (одна из первых статей про триплет-лосс), [N Pairs Loss](https://papers.nips.cc/paper/2016/file/6b180037abbebea991d8b1232f8a8ca9-Paper.pdf), [Gradient Surgery](https://arxiv.org/pdf/2201.11307.pdf) (+ походить по ссылкам из статьи) **и статьи из**[**Metric Learning Reality Check**](https://arxiv.org/pdf/2003.08505.pdf) (где автор попытался воспроизвести результаты и оказалось, что не всё так прекрасно). Плюс, совершенно внезапно, рекомендую статьи про SSL (потому что как мы помним self-supervised это тот же метрик лёрнинг, только unsupervised): например, [вот эту](https://arxiv.org/pdf/1805.01978v1.pdf) (из-за мемори-банка), [MoCo v2](https://arxiv.org/pdf/2003.04297.pdf) (из-за моментум энкодера). Ну а если понравилось читать про SSL, то можно ещё [SimSiam](https://arxiv.org/pdf/2011.10566.pdf) и то с чем авторы сравниваются (BYOL, SimCLR, SwAV), не то что бы можно оттуда вынести что-то полезное для метрик лёрнинга, но область классная и статьи интересные + вместе с [CLIP](https://openai.com/blog/clip/) могут быть использованы как претрейны ([ссылка](https://www.youtube.com/watch?v=T9XSU0pKX2E) на CLIP для тех, кому ближе видеоформат).

#### Заметки из практики

Триплет-лосс — работает.

Софт-версия триплет-лосса — тоже, но иногда хуже.

Ауги — ощутимо влияют на качество модели.

Выбор претрейна — критически важно (например, у меня из-за этого не заводился ArcFace: в torchvision в один момент поменялись дефолтные веса для претрейна RN50 и это не давало мне выйти к хорошим метрикам, просадка была 7-8 пунктов). 

Хорошие претрейны для ViT — [DINO](https://www.youtube.com/watch?v=h3ij3F3cPIk) и [CLIP](https://www.youtube.com/watch?v=T9XSU0pKX2E).

Сэмлеры и майнеры — очень важно для контрастив подхода. Стоит уделить этому много времени.

Мемори банк — работает (особенно хорошо в сочетании с майнерами).

Не знаете по какой метрике сравниваться — сравнивайтесь по MAP@k.

Размер эмбеддинга может влиять на сходимость вашего подхода, подбирайте с осторожностью.

Разница между хорошим претрейном и файнтьюном на вашем датасете обычно в районе 10-50 пунктов MAP@5, поэтому файнтьюн стоит потраченного на него времени.

Хороший бейзлайн — можно [взять](https://github.com/OML-Team/open-metric-learning/#zoo) в нашей библиотеке, мы много времени потратили на эксперименты и там неплохие дефолты.

#### Меня заинтересовало, какие библиотеки использовать/какие хорошие статьи по тематике прочитать?

Во-первых, **статьи и блоги** :

[Про контрастив подходы и SSL](https://lilianweng.github.io/posts/2021-05-31-contrastive/), здесь написано не только про картинки, но и про текст, и про звук, больше внимания всё-таки уделено unsupervised, но блог очень хороший.

[Metric Learning Reality Check](https://arxiv.org/pdf/2003.08505.pdf) — статья, которая когда-то сильно перевернула представление о том, насколько хорошо работают методы из статей про метрик лёрнинг. Уже немножко не новая по меркам области (2020-ый год), но всё равно обязательная к прочтению.

[Gradient Surgery](https://arxiv.org/pdf/2201.11307.pdf) — классная статья про то как можно миксовать градиенты в контрастив подходах, беря направление одного и магнитуду другого.

Во-вторых, **библиотеки** :

Если вы хотите чего-то серьёзного и продакшн-реди, то [OML](https://github.com/OML-Team/open-metric-learning) (наша библиотечка) для обучения и, если не хватает лоссов, стырить их из [PML](https://kevinmusgrave.github.io/pytorch-metric-learning/losses/). Почему именно так, а не целиком всё в PML/OML? OML появился, когда оказалось слишком сложно встраивать PML в продакшн, но при этом PML более старая библиотека, а поэтому в ней собралось много всего, пока что не имплементированного в OML.

Если же вы хотите учить только последний слой сетки, без твиков всего остального, то [Quaterion](https://quaterion.qdrant.tech/). Библиотека больше в стиле "обучу на ноутбуке для своего петпроджекта, который в целом вообще о другом, но пусть тут и метрик лёрнинг будет". Кстати, работает и с NLP.

В-третьих, **соревнования** :

Google Landmark Recognition [2019](https://www.kaggle.com/competitions/landmark-recognition-2019/discussion/95847), [2020](https://www.kaggle.com/competitions/landmark-recognition-2020/discussion/200506), [2021](https://www.kaggle.com/competitions/landmark-recognition-2021/discussion/276436).

[Google Universal Embedding 2022](https://www.kaggle.com/competitions/google-universal-image-embedding/discussion?sort=votes) (кстати, не удивлюсь если это для Google Lens).

[Facebook AI Image Similarity Challenge](https://www.drivendata.org/competitions/79/competition-image-similarity-1-dev/).

#### Заключение

Мерик лёрнинг — прикольная область о которой почему-то не очень много говорят. При этом, для того чтобы использовать какие-то базовые подходы на практике, не требуется много усилий, в то время как результат может быть неплохим.

  


________________________________________

***** Про более корректное определение: поиск параметризации θ метрики F(**x** , **y** , θ), такой, чтобы она соответствовала близости объектов **x** и **y** в рамках поставленной задачи. Но это в большинстве случаев можно воспринимать как поиск параметризации θ для M(Ф(**x** , θ), Ф(**y** , θ)), где M(·, ·) — евклидово или косинусное расстояние, а Ф(·, θ) — нейронка с параметрами θ.
