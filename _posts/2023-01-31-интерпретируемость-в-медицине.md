---
date: 2023-01-31 15:31:20 +0000
excerpt: Пост посвящен проблеме интерпретируемости в медицинских ИИ-системах, где
  врачи хотят понимать, как алгоритмы принимают решения при анализе рентгенологических
  снимков. Рассматриваются различные методы интерпретации результатов - от клинических
  концептов до генерации текстовых заключений, которые помогают объяснить логику работы
  нейронных сетей и повысить доверие медицинских специалистов к технологиям искусственного
  интеллекта.
layout: post
source_type: telegraph
source_url: https://telegra.ph/Interpretiruemost-v-medicine-01-30
tags:
- ml
- жека
telegram_url: https://t.me/varim_ml/81
telegraph_url: https://telegra.ph/Interpretiruemost-v-medicine-01-30
title: Интерпретируемость в медицине
views: 3324
---

# Интерпретируемость в медицине  


[Evgenii Nikitin](https://t.me/crazyfrogspb)  


Так совпало, что я недавно прочёл статью [Transparency of deep neural networks for medical image analysis](https://www.sciencedirect.com/science/article/pii/S0010482521009057) и [пост от канала Reliable ML про интерпретируемость](https://habr.com/ru/company/ods/blog/709688/). Я работаю в сфере медицины уже почти пять лет, и всё это время постоянно где-то на орбите внимания мелькает эта тема.

Что такое интерпретируемость, если решается задача классификации всего рентгенологического исследования - в целом понятно. Врачи не доверяют системам, которые просто говорят "тут где-то на картинке есть рак", а значит нужны какие-то методы, которые будут "объяснять" итоговое предсказание. Их придумано довольно много - разнообразные виды GradCAMа, окклюзия, LIME. Из коробки многие из них можно взять из библиотеки [Captum](https://captum.ai/tutorials/Resnet_TorchVision_Interpret) для Pytorch.

![](/assets/images/5088e9f0.png)Несколько месяцев в 2020 году GradCAM работал у нас в продакшне

Однако, жизнь показывает, что качество локализации клинически значимых признаков у этих методов, мягко говоря, неудовлетворительное. При этом вряд ли кто-то будет всерьёз рассматривать ИИ-систему, которая не решает задачу локализации - детекции или сегментации. Да и реально хороших метрик на чистой классификации достичь удаётся разве что при наличии очень больших, чистых датасетов. На данный момент у нас четыре системы в проде, из них одна - это детекция, две - инстанс-сегментация, и ещё одна - семантическая сегментация.

Когда система умеет локализовывать области интереса и присваивать им класс (например, злокачественное образование, лимфоузел и так далее), вопрос интерпретируемости как будто бы отпадает. Действительно, несколько лет мы работали, вспоминая про интерпретируемость только на внутренних митапах.

### Зачем нужна интерпретируемость?

В прошлом году мы решили, что не Москвой единой, и начали разводить активности и в других регионах - и в государственных, и в коммерческих клиниках. Процесс продажи в 99% случаев включает тестирование системы на данных заказчика. Кто-то смотрит только на агрегированные результаты и метрики, но большинство главврачей и медицинских директоров любят визуально оценить результаты работы системы. Кроме того, с сентября 2022 года в Московском эксперименте появилась процедура [клинической оценки](https://mosmed.ai/documents/200/%D0%9A%D0%BB%D0%B8%D0%BD%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D0%BE%D1%86%D0%B5%D0%BD%D0%BA%D0%B0_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D1%8B_%D0%98%D0%98-%D1%81%D0%B5%D1%80%D0%B2%D0%B8%D1%81%D0%BE%D0%B2_22.08.2022.pdf). Врачи-эксперты ежемесячно оценивают результаты работы системы на случайно выбранных 80 исследованиях. В общем, количество обратной связи и вопросов выросло в разы.

Вот примеры вопросов и замечаний:

  * "Почему ИИ выделил эту область как патологию, а соседнюю нет? Они же выглядят почти одинаково!"
  * "Почему [суммация теней](https://htm.fandom.com/wiki/Summation_Shadow) и артефакты оцифровки расценены как злокачественные образования?"
  * "Почему патология выделена на одной [проекции](https://radiopaedia.org/articles/mammography-views), а на другой нет?"
  * "Почему выделена область потенциальной патологии, но общая оценка исследования - норма"?



Подобные "косяки" вызывают недоумение врачей и ощутимо снижают вероятность продажи. Что можно делать?

  * Улучшать системы за счёт дообучения и изменения архитектуры
  * Добавлять разные эвристики и хаки, чтоб избегать определённых типов ошибок
  * Вести просветительскую работу, чтобы врачи лучше понимали источники тех или иных ошибок и общую суть работы ИИ-систем
  * Добавлять механизмы интерпретации и объяснения предсказаний, которые помогут отвечать на эти "почему"



Я как раз и хочу разобрать некоторые способы интерпретации из статьи из первого абзаца и привести примеры использования из нашей практики.

### Способы интерпретации

#### Клинические концепты

![](/assets/images/fe758758.png)

Суть этого метода достаточно проста, но при этом привлекательна. Вместо прямого предсказания класса RoI (Region-of-Interest) с помощью сетки, будем сначала определять его различные свойства, связанные с текстурой, формой, плотностью относительно окружающей ткани, размером. А уже на основе этих свойств мы можем на основе правил или с помощью простой линейной модели определять конкретный тип объекта - например, злокачественный он или доброкачественный. Звучит крайне приятно - для каждого предсказания мы можем объяснить врачу, почему оно именно такое. Метод, конечно же, не идеален:

  * Скорее всего, для корректного расчёта большинства признаков потребуется очень точная сегментация контура RoI
  * Метрики могут упасть по сравнению с прямой классификацией
  * Модель может просто пропустить нужный RoI, и тогда вопросы всё равно возникнут
  * Некоторые клинические признаки сложно перевести в численную форму



Мы используем похожую идею для присваивания общего риска патологии на исследовании. Вместо того, чтобы напрямую решать задачу бинарной классификации (0 - норма, 1 - патология) по картинкам, мы используем найденные объекты, их вероятности, классы и размеры в качестве фичей простой мета-модели - например, LightGBM.

#### Concept attribution

![](/assets/images/82e77401.png)

Схожая по духу идея, которая позволяет решить один из недостатков предыдущего метода - вероятное падение метрик. И снова ничего сложного - считаем так называемые [радиомические фичи](https://pyradiomics.readthedocs.io/en/latest/features.html) объекта (как базовые, характеризующие форму или размер, так и специфические для задачи), а затем строим модели, которые пытаются предсказать значение каждой фичи по репрезентациям из нашей нейронки. С помощью этих моделей можно для каждого входного изображения оценить чувствительность конечного предсказания к значениям тех или иных радиомических фичей. Подробности можно узнать в этой [статье](https://arxiv.org/abs/1711.11279) и в [этой](https://arxiv.org/abs/1904.04520).

![](/assets/images/d1fbf148.png)Хорошая фича для образований на маммографических исследованиях, форма распределения этих углов позволяет оценить наличие "шипов" в форме объекта

Мы пробовали такой подход для маммографии - есть любопытные результаты, некоторые фичи прям хорошо можно предсказать по нейронным репрезентациям. До прода пока не докатилось, но помогло сгенерить гипотезы по добавлению hand-crafted фичей в сетку.

#### Интерпретация по кейсам

  


![](/assets/images/54bc61d3.png)Из https://ieeexplore.ieee.org/document/9448270

Ещё одна группа методов основана на поиске похожих кейсов среди библиотеки патологий. Мы рассматривали такую идею - дать врачу возможность выделять область на изображении, вычислять её репрезентацию, а затем искать в векторной базе данных типа [Milvus](https://milvus.io/) похожие области среди наших размеченных данных. Опять же - пока осталось на уровне идеи.

#### Counterfactual explanation

![](/assets/images/7d3e289a.png)

Метод, отсылающий нас к посту про [робастное обучение](/Robastnoe-obuchenie-08-10) \- берём RoI и пытаемся каким-то способом (например, генеративной сетью) изменить его так, чтобы изменить предсказанный класс - например, со злокачественного образования на доброкачественное или background. Изменённые участки могут подсказать, на что смотрит сетка, и какие свойства объекта для неё оказались решающими. Сам не пробовал, но интуитивно сомневаюсь, что получатся визуально адекватные пертурбации.

#### Генерация заключений

Существует большая группа статей, которые нацелены на генерацию текстового заключения по медицинскому изображению. Подходы есть разные - с использованием фиксированного словаря, свободная генерация, заполнение пустых мест в шаблоне. В продакшне ничего лично не видел, хотя мы думали об этом много.

### Что в итоге?

Как вы, наверное, догадались из текста - у нас это всё пока остаётся на уровне рисёча и развлечений. Причина проста - нет уверенности, что затраченное время окупится каким-то повышенным доверием от пользователей. На данном этапе кажется, что стоит больше внимания уделить просто улучшению качества работы моделей - до идеала нам и нашим конкурентам пока далеко. Хотя свои интересные применения у этих методов когда-нибудь найдутся - например, в образовательном процессе молодых рентгенологов или автоматической генерации детальных текстовых заключений.

  

